{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readme:\n",
    "\n",
    "\n",
    "We encourage you to explore more functionalities in 'Python for Data Analysis, 3E' by Wes McKinney, Chapter 10: 'Data Aggregation and Group Operations'.</br>\n",
    "Link: https://wesmckinney.com/book/data-aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Task 1 </b></h3>\n",
    "<p>\n",
    "Given below dataframe, sum the values in 'data1' grouping them by 'key1' and 'key2'. </br>\n",
    "Run unstack() on the result and analyze what it does.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped sum:\n",
      " key1  key2\n",
      "a     1      -0.277449\n",
      "      2       0.515371\n",
      "      <NA>   -1.517096\n",
      "b     1       0.509951\n",
      "      2       1.129948\n",
      "NaN   1       0.922618\n",
      "Name: data1, dtype: float64\n",
      "\n",
      "Unstacked result:\n",
      " key2      1         2         <NA>\n",
      "key1                              \n",
      "a    -0.277449  0.515371 -1.517096\n",
      "b     0.509951  1.129948       NaN\n",
      "NaN   0.922618       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"key1\": [\"a\", \"a\", None, \"b\", \"b\", \"a\", None],\n",
    "    \"key2\": pd.Series([1, 2, 1, 2, 1, None, 1], dtype=\"Int64\"),\n",
    "    \"data1\": np.random.standard_normal(7),\n",
    "    \"data2\": np.random.standard_normal(7)\n",
    "})\n",
    "\n",
    "# Group by key1 and key2, summing data1\n",
    "grouped = df.groupby([\"key1\", \"key2\"], dropna=False)[\"data1\"].sum()\n",
    "\n",
    "# Display the result before unstacking\n",
    "print(\"Grouped sum:\\n\", grouped)\n",
    "\n",
    "# Unstack the result\n",
    "unstacked = grouped.unstack()\n",
    "print(\"\\nUnstacked result:\\n\", unstacked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Task 2 </b></h3>\n",
    "<p>\n",
    "Can you sum the values in 'data1' of the above dataframe grouping the result by below arrays of data? </br>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA  2005    0.562916\n",
      "    2006    1.369498\n",
      "OH  2005    0.023481\n",
      "    2006   -1.240904\n",
      "Name: data1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Original DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"key1\": [\"a\", \"a\", None, \"b\", \"b\", \"a\", None],\n",
    "    \"key2\": pd.Series([1, 2, 1, 2, 1, None, 1], dtype=\"Int64\"),\n",
    "    \"data1\": np.random.standard_normal(7),\n",
    "    \"data2\": np.random.standard_normal(7)\n",
    "})\n",
    "\n",
    "# Arrays to group by\n",
    "states = np.array([\"OH\", \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\n",
    "years = [2005, 2005, 2006, 2005, 2006, 2005, 2006]\n",
    "\n",
    "# Group by arrays and sum 'data1'\n",
    "grouped = df[\"data1\"].groupby([states, years]).sum()\n",
    "\n",
    "# Display the result\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Task 3 </b></h3>\n",
    "<p>\n",
    "What if you want to calculate sum on every column which is numeric grouping the result by 'key2'? </br>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         data1     data2\n",
      "key2                    \n",
      "1     0.103191  0.673154\n",
      "2     0.269481 -1.574802\n"
     ]
    }
   ],
   "source": [
    "# Group by 'key2' and sum all numeric columns\n",
    "grouped_sum = df.groupby(\"key2\").sum(numeric_only=True)\n",
    "\n",
    "# Display the result\n",
    "print(grouped_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Task 4 </b></h3>\n",
    "<p>\n",
    "Group the dataframe's data by 'key1' and calculate the size and count of each group with NA values included. </br>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Size (includes NA values):\n",
      "key1\n",
      "a      3\n",
      "b      2\n",
      "NaN    2\n",
      "dtype: int64\n",
      "\n",
      "Group Count (non-NA values per column):\n",
      "      key2  data1  data2\n",
      "key1                    \n",
      "a        2      3      3\n",
      "b        2      2      2\n",
      "NaN      2      2      2\n"
     ]
    }
   ],
   "source": [
    "# Group by 'key1' and calculate size\n",
    "group_size = df.groupby(\"key1\", dropna=False).size()\n",
    "\n",
    "# Group by 'key1' and calculate count (non-NA entries per column)\n",
    "group_count = df.groupby(\"key1\", dropna=False).count()\n",
    "\n",
    "# Display results\n",
    "print(\"Group Size (includes NA values):\")\n",
    "print(group_size)\n",
    "print(\"\\nGroup Count (non-NA values per column):\")\n",
    "print(group_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Task 5 </b></h3>\n",
    "<p>\n",
    "Grouping with Dictionaries and Series.</br>\n",
    "Can you sum the values in 'people' dataframe grouping them by 'mapping' dictionary on column axis? </br>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           blue       red\n",
      "Joe    1.847562  0.409425\n",
      "Steve -0.595276  0.146231\n",
      "Wanda -0.519190 -0.764807\n",
      "Jill   0.403982  1.568263\n",
      "Trey   1.467491  0.940447\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the DataFrame\n",
    "people = pd.DataFrame(np.random.standard_normal((5, 5)),\n",
    "                      columns=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "                      index=[\"Joe\", \"Steve\", \"Wanda\", \"Jill\", \"Trey\"])\n",
    "\n",
    "# Mapping dictionary\n",
    "mapping = {\n",
    "    \"a\": \"red\", \n",
    "    \"b\": \"red\", \n",
    "    \"c\": \"blue\", \n",
    "    \"d\": \"blue\", \n",
    "    \"e\": \"red\", \n",
    "    \"f\": \"orange\"  # Not present in DataFrame, will be ignored\n",
    "}\n",
    "\n",
    "# Updated approach: Transpose, group by, then transpose back\n",
    "grouped = people.T.groupby(mapping).sum().T\n",
    "\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Task 6 </b></h3>\n",
    "<p>\n",
    "Grouping with Functions.</br>\n",
    "Any function passed as a group key will be called once per index value (or once per column value if using axis=\"columns\"), with the return values being used as the group names. </br>\n",
    "More concretely, consider the example DataFrame from the previous section, which has peopleâ€™s first names as index values. </br>\n",
    "Suppose you wanted to group by name length. While you could compute an array of string lengths, it's simpler to just pass the 'len' function.</br>\n",
    "Run below and analyze the result. </br>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b         c         d         e\n",
      "3  0.710836  1.376156 -1.492009  0.541408 -1.464937\n",
      "4  1.454821 -2.524155 -2.453808  1.182791  0.897367\n",
      "5 -0.940448 -0.595841  1.007527  1.366857 -0.121438\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the DataFrame\n",
    "people = pd.DataFrame(np.random.standard_normal((5, 5)),\n",
    "                      columns=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "                      index=[\"Joe\", \"Steve\", \"Wanda\", \"Jill\", \"Trey\"])\n",
    "\n",
    "# Group by length of index (name length) and sum\n",
    "grouped = people.groupby(len).sum()\n",
    "\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Task 7 </b></h3>\n",
    "<p>\n",
    "Aggregations refer to any data transformation that produces scalar values from arrays.</br>\n",
    "To use your own aggregation functions, pass any function that aggregates an array to the aggregate method or its short alias 'agg'.</br>\n",
    "Run below code and analyze the result.</br>\n",
    "Note: Custom aggregation functions are generally much slower than the optimized built-in functions. This is because there is some extra overhead (function calls, data rearrangement) in constructing the intermediate group data chunks. </br>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key2</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1</td>\n",
       "      <td>0.367722</td>\n",
       "      <td>2.274187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>0.078564</td>\n",
       "      <td>1.328339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      key2     data1     data2\n",
       "key1                          \n",
       "a        1  0.367722  2.274187\n",
       "b        1  0.078564  1.328339"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby(\"key1\")\n",
    "\n",
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()\n",
    "\n",
    "grouped.agg(peak_to_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      key2     data1     data2\n",
      "key1                          \n",
      "a        1  4.684470  3.074428\n",
      "b        1  1.706936  3.344879\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"key1\": [\"a\", \"a\", None, \"b\", \"b\", \"a\", None],\n",
    "    \"key2\": pd.Series([1, 2, 1, 2, 1, None, 1], dtype=\"Int64\"),\n",
    "    \"data1\": np.random.standard_normal(7),\n",
    "    \"data2\": np.random.standard_normal(7)\n",
    "})\n",
    "\n",
    "# Group by 'key1'\n",
    "grouped = df.groupby(\"key1\")\n",
    "\n",
    "# Custom aggregation function: range (max - min)\n",
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()\n",
    "\n",
    "# Apply aggregation\n",
    "result = grouped.agg(peak_to_peak)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
